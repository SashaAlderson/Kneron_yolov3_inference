{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1269fef9",
   "metadata": {},
   "source": [
    "### Clone keras yolov3 repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27713651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data1\n",
      "fatal: destination path 'keras_yolo3' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "%cd /data1\n",
    "!git clone https://github.com/qqwweee/keras-yolo3.git keras_yolo3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d4477c",
   "metadata": {},
   "source": [
    "### Load and convert yolov3 model to keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabed4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data1/keras_yolo3\n",
      "--2021-08-24 08:12:35--  https://pjreddie.com/media/files/yolov3.weights\n",
      "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
      "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 248007048 (237M) [application/octet-stream]\n",
      "Saving to: ‘yolov3.weights.1’\n",
      "\n",
      "yolov3.weights.1     59%[==========>         ] 141.12M  7.76MB/s    eta 13s    "
     ]
    }
   ],
   "source": [
    "%cd keras_yolo3\n",
    "!wget https://pjreddie.com/media/files/yolov3.weights\n",
    "!python convert.py yolov3.cfg yolov3.weights /data1/yolo.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95ad0e3",
   "metadata": {},
   "source": [
    "### Download kneron images for further quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa881f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /data1\n",
    "!wget http://doc.kneron.com/docs/toolchain/res/test_image10.zip\n",
    "!unzip test_image10.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e27eb32",
   "metadata": {},
   "source": [
    "### Copy image for model's testing in different convertation stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f9ab1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /data1\n",
    "!cp /workspace/E2E_Simulator/app/test_image_folder/yolo/000000350003.jpg ./."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58014198",
   "metadata": {},
   "source": [
    "### Run example script test.py to convert yolov3 from keras to nef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ab9d01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python /workspace/Kneron_yolov3_inference/test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75145bc",
   "metadata": {},
   "source": [
    "### Make changes to E2E simulator in order to use it with multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748b838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp /workspace/Kneron_yolov3_inference/model.py  /data1/keras_yolo3/yolo3/model.py \n",
    "!cp /workspace/Kneron_yolov3_inference/nef.py /workspace/E2E_Simulator/python_flow/nef/nef.py  \n",
    "!cp /workspace/Kneron_yolov3_inference/kneron_inference.py /workspace/E2E_Simulator/python_flow/kneron_inference.py "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd9ed06",
   "metadata": {},
   "source": [
    "## Download COCO dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9502afba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir /workspace/COCO \n",
    "%cd /workspace/COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a76b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -c http://images.cocodataset.org/zips/val2017.zip\n",
    "!unzip -q val2017.zip\n",
    "!rm val2017.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b406887",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv val2017 images \n",
    "!mkdir val2017\n",
    "!mv images val2017/images\n",
    "!mkdir /workspace/COCO/val2017/predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3769b55e",
   "metadata": {},
   "source": [
    "# Yolov3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c13969",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /workspace/Kneron_yolov3_inference/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d9120f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python parallel.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57be7ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script will run untill no more predictions to be done.\n",
    "We recommend to increase number of models, if you're using it to simulate Kneron 720, \n",
    "since this simulator uses only one thread.\n",
    "\"\"\"\n",
    "\n",
    "import multiprocessing\n",
    "import os\n",
    "from time import time\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "tic = time() \n",
    "step = 5 # images per iteration of script\n",
    "models = 5 # number of models running in parallel\n",
    "init = 3 # time between model's initialization\n",
    "threads = 16 # number of workers for each model, works only for 520 model\n",
    "path = '/workspace/COCO/val2017' # path to validation directory\n",
    "predictions = path + '/' + 'predictions'\n",
    "labels= path + '/' +  'images'\n",
    "\n",
    "\n",
    "def missed(predictions, labels):    \n",
    "    predictions =[f[:12] for f in listdir(predictions) if isfile(join(predictions, f))]    \n",
    "    labels =[f[:12] for f in listdir(labels) if isfile(join(labels, f))]\n",
    "    predicted = list(set(predictions) & set(labels))\n",
    "    not_predicted = labels\n",
    "    \n",
    "    for element in predicted:\n",
    "        #print(element)\n",
    "        not_predicted.remove(element) \n",
    "\n",
    "    return not_predicted\n",
    "\n",
    "# Check if there is all predictions\n",
    "not_predicted = missed(predictions, labels)\n",
    "all_processes =[]\n",
    "for i in range(models):\n",
    "    all_processes.append('parallel.py --path {} --model {} --step {} --init {} --conf-t 0.001 --threads {}'.format(path, i, step, init, threads))\n",
    "\n",
    "while len(not_predicted):\n",
    "    # This block of code enables us to call the script from command line.                                                                                \n",
    "    def execute(process):                                                             \n",
    "        os.system(f'python {process}')                                       \n",
    "\n",
    "\n",
    "    process_pool = multiprocessing.Pool(processes = models)                                                        \n",
    "    process_pool.map(execute, all_processes)\n",
    "    \n",
    "    # Check if there is all predictions\n",
    "    not_predicted = missed(predictions, labels) \n",
    "    \n",
    "print(\"Script ran for \", time() - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b26e7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python parallel.py --demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1052ef36",
   "metadata": {},
   "source": [
    "# mAP evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46342dc",
   "metadata": {},
   "source": [
    "### Download COCO anotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204ec34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /workspace/COCO/val2017\n",
    "!wget -c http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
    "!wget https://raw.githubusercontent.com/matlab-deep-learning/Object-Detection-Using-Pretrained-YOLO-v2/main/%2Bhelper/coco-classes.txt\n",
    "!unzip annotations_trainval2017.zip\n",
    "!mkdir labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94de366a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "f=open(\"annotations/instances_val2017.json\")\n",
    "coco= json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd92fa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe1dacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COCO classes for inference\n",
    "namescoco = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "        'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "        'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
    "        'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
    "        'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "        'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
    "        'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "        'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\n",
    "        'hair drier', 'toothbrush']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854095af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 91 classes from COCO's paper\n",
    "names91 = ['empty', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat',\n",
    "           'traffic light', 'fire hydrant', 'empty', 'stop sign', 'parking meter', 'bench', 'bird', 'cat',\n",
    "           'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'empty', 'backpack', \n",
    "           'umbrella', 'empty', 'empty', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', \n",
    "           'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', \n",
    "           'bottle', 'empty', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', \n",
    "           'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', \n",
    "           'potted plant', 'bed', 'empty', 'dining table', 'empty', 'empty', 'toilet', 'empty', 'tv', 'laptop', \n",
    "           'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', \n",
    "           'empty', 'book','clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd8f8bc",
   "metadata": {},
   "source": [
    "### Generate labels in yolo.txt format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c3669c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(coco['images'])):\n",
    "    bbox = []\n",
    "    for j in range(len(coco['annotations'])):\n",
    "        if coco['annotations'][j][\"image_id\"] == coco['images'][i][\"id\"]: \n",
    "            x = coco['annotations'][j][\"bbox\"][0]\n",
    "            y = coco['annotations'][j][\"bbox\"][1]\n",
    "            w =  coco['annotations'][j][\"bbox\"][2]\n",
    "            h = coco['annotations'][j][\"bbox\"][3]\n",
    "            width = coco['images'][i]['width']\n",
    "            height = coco['images'][i]['height']\n",
    "            # Convert class id to 80 classes version\n",
    "            cat = coco['annotations'][j]['category_id']\n",
    "            cls = names91[cat]\n",
    "            cls = namescoco.index(cls)\n",
    "            bbox.append(str(cls) + \" \" + str((x+w/2)/width) + \" \" + str((y+h/2)/height)+\" \" + str(w/width)+\" \" + str(h/height)) \n",
    "            \n",
    "    bbox = '\\n'.join(bbox)\n",
    "    with open('/workspace/COCO/val2017/labels/{}.txt'.format(coco['images'][i][\"file_name\"][:12]), 'w') as f:\n",
    "        f.write(str(bbox))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9818d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate predictions on these labels with https://github.com/rafaelpadilla/review_object_detection_metrics\n",
    "# Download all needed files that located under /workspace/COCO/val2017 and use it to calculate mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f505a6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your results should look like this:\n",
    "\"\"\"\n",
    "COCO METRICS:\n",
    "AP: 0.30763665649871075\n",
    "AP50: 0.5915429205728568\n",
    "AP75: 0.29242076553561813\n",
    "APsmall: 0.10837458746989537\n",
    "APmedium: 0.29600038344642876\n",
    "APlarge: 0.4424104857026416\n",
    "AR1: 0.2567070573097393\n",
    "AR10: 0.4102890791340148\n",
    "AR100: 0.4285984240348608\n",
    "ARsmall: 0.23691939502550804\n",
    "ARmedium: 0.44522361970282825\n",
    "ARlarge: 0.5428652114891923\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
